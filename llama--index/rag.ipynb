{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5766c27",
   "metadata": {},
   "source": [
    "## RAG System with HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d9b0d",
   "metadata": {},
   "source": [
    "LOAD -> INDEX -> QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8436fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fredr\\OneDrive\\Desktop\\llm-utilities\\llm\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fredr\\OneDrive\\Desktop\\llm-utilities\\llm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.response.pprint_utils import pprint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe684dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 89)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "\n",
    "type(documents), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54931499",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful Q&A assistant. Your goal is to answer questins as accurately \n",
    "as possible based on the instructions and context provided.\n",
    "\"\"\"\n",
    "\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c293164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 09:49:25,034 - INFO - Use pytorch device_name: cpu\n",
      "2025-10-24 09:49:25,036 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "embed_model = LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    ")\n",
    "llm = Groq(\n",
    "    api_key=os.environ[\"GROQ_API_KEY\"], \n",
    "    system_prompt=system_prompt,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    context_window_size=4096,\n",
    "    max_new_tokens=256,\n",
    "    tokenizer_name=\"openai/gpt-oss-120b\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    device_map=\"auto\",\n",
    "    generate_kwargs={\"temperature\": 0.7, \"do_sample\": False},\n",
    "    model_kwargs={\"torch_dtype\": \"float16\", \"load_in_8bit\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d82d8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "764fe687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 89/89 [00:00<00:00, 379.54it/s]\n",
      "Generating embeddings: 100%|██████████| 147/147 [01:36<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, llm=llm, chunk_size=1024, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ec884bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:15:08,431 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: The Attention mechanism is a component of neural network models that computes weighted relationships between elements of an\n",
      "input sequence, allowing the model to focus on the most relevant tokens when processing each word. By assigning attention scores, it\n",
      "captures dependencies that may span long distances in the text and reflects structural cues such as grammatical relationships, enabling\n",
      "different attention heads to specialize in distinct linguistic tasks.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 10:15:09,122 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: YOLO is a unified object‑detection system that uses a single convolutional neural network to directly predict multiple\n",
      "bounding boxes and their class probabilities from whole images, enabling real‑time detection with high speed and accuracy.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\"What is Attention mechanism? Start the answer with 'The Attention mechanism is...'\")\n",
    "pprint_response(response, wrap_width=140)\n",
    "print()\n",
    "\n",
    "response = query_engine.query(\"What is YOLO?\")\n",
    "pprint_response(response, wrap_width=140)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
